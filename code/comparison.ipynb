{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import (\n",
    "    RFE,\n",
    "    SelectFromModel,\n",
    "    SelectKBest,\n",
    "    SequentialFeatureSelector,\n",
    "    f_classif,\n",
    "    mutual_info_classif,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from utils import (\n",
    "    experiment,\n",
    "    get_data,\n",
    "    get_param_combinations,\n",
    "    get_params_json,\n",
    "    save_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change value before running experiment\n",
    "filename = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO remove - this is for testing the script!\n",
    "# X = X[:100]\n",
    "# y = y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(feature_selectors, classifiers, ks, results, train_test_seeds=[42]):\n",
    "    for fs in feature_selectors:\n",
    "        for clf in classifiers:\n",
    "            for k in ks:\n",
    "                # Generate parameter combinations\n",
    "                fs_cls, fs_params, k_param_name, requires_estimator = fs\n",
    "                clf_cls, clf_params = clf\n",
    "\n",
    "                fs_param_combinations = get_param_combinations(fs_params)\n",
    "                clf_param_combinations = get_param_combinations(clf_params)\n",
    "\n",
    "                for fs_params in fs_param_combinations:\n",
    "                    for clf_params in clf_param_combinations:\n",
    "                        # Run experiment\n",
    "                        start = time.time()\n",
    "                        accs, accs_top_20pc = experiment(\n",
    "                            X,\n",
    "                            y,\n",
    "                            fs_cls,\n",
    "                            fs_params,\n",
    "                            clf_cls,\n",
    "                            clf_params,\n",
    "                            k,\n",
    "                            k_param_name,\n",
    "                            requires_estimator,\n",
    "                            train_test_seeds,\n",
    "                        )\n",
    "                        elapsed = time.time() - start\n",
    "                        elapsed = elapsed / len(train_test_seeds)\n",
    "\n",
    "                        acc = accs.mean()\n",
    "                        acc_std = accs.std()\n",
    "                        acc_top_20pc = accs_top_20pc.mean()\n",
    "\n",
    "                        # Save results\n",
    "                        result = (\n",
    "                            fs_cls.__name__,\n",
    "                            get_params_json(fs_params),\n",
    "                            clf_cls.__name__,\n",
    "                            get_params_json(clf_params),\n",
    "                            k,\n",
    "                            acc,\n",
    "                            acc_std,\n",
    "                            acc_top_20pc,\n",
    "                            elapsed,\n",
    "                        )\n",
    "\n",
    "                        print(result)\n",
    "                        print(f\"Elapsed time: {elapsed:.2f}s\\n\")\n",
    "                        results.append(result)\n",
    "                        save_results(results, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - parameters of GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"comparison\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (\n",
    "        SelectKBest,\n",
    "        {\"score_func\": [f_classif, mutual_info_classif]},\n",
    "        \"k\",\n",
    "        False,\n",
    "    ),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        GradientBoostingClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.1, 0.2],\n",
    "            \"subsample\": [0.5, 1],\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "# ks = np.concatenate([np.arange(1, 20, 1), np.arange(20, 45, 5)])\n",
    "ks = np.arange(1, 21, 3)\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: simple feature selection with various classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (SelectKBest, {\"score_func\": [mutual_info_classif]}, \"k\", False),\n",
    "]\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    (GradientBoostingClassifier, {}),\n",
    "    (RandomForestClassifier, {\"random_state\": [42]}),\n",
    "    (SVC, {\"kernel\": [\"linear\", \"rbf\"], \"probability\": [True], \"random_state\": [42]}),\n",
    "    (LinearDiscriminantAnalysis, {}),\n",
    "    (QuadraticDiscriminantAnalysis, {}),\n",
    "]\n",
    "\n",
    "ks = np.arange(1, 21, 3)\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: simple classifier with various feature selectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (RFE, {}, \"n_features_to_select\", True),\n",
    "    (SelectFromModel, {\"threshold\": [-np.inf]}, \"max_features\", True),\n",
    "    (\n",
    "        SequentialFeatureSelector,\n",
    "        {\n",
    "            \"direction\": [\n",
    "                # \"backward\", # too slow\n",
    "                \"forward\",\n",
    "            ],\n",
    "            \"n_jobs\": [-2],\n",
    "        },\n",
    "        \"n_features_to_select\",\n",
    "        True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (RandomForestClassifier, {\"random_state\": [42]}),\n",
    "]\n",
    "\n",
    "ks = np.arange(1, 21, 3)\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: SelectFromModel with best classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"comparison_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (SelectFromModel, {\"threshold\": [-np.inf]}, \"max_features\", True),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        RandomForestClassifier,\n",
    "        {\"random_state\": [42], \"n_jobs\": [-2], \"n_estimators\": [100, 200]},\n",
    "    ),\n",
    "]\n",
    "\n",
    "ks = np.arange(1, 21, 1)\n",
    "train_test_seeds = list(range(42, 47))\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results, train_test_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"comparison_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 0.669\n",
      "43 0.683\n",
      "44 0.68\n",
      "45 0.684\n",
      "46 0.679\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 5, 0.679, 0.005329165037789696, 0.768, 45.349039268493655)\n",
      "Elapsed time: 45.35s\n",
      "\n",
      "42 0.693\n",
      "43 0.702\n",
      "44 0.712\n",
      "45 0.697\n",
      "46 0.7\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 6, 0.7008000000000001, 0.0063686733312362685, 0.766, 48.50391154289245)\n",
      "Elapsed time: 48.50s\n",
      "\n",
      "42 0.689\n",
      "43 0.695\n",
      "44 0.698\n",
      "45 0.698\n",
      "46 0.693\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 7, 0.6946, 0.0033823069050575557, 0.779, 44.32134146690369)\n",
      "Elapsed time: 44.32s\n",
      "\n",
      "42 0.679\n",
      "43 0.693\n",
      "44 0.701\n",
      "45 0.691\n",
      "46 0.698\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 8, 0.6923999999999999, 0.007578918128598534, 0.781, 43.42149753570557)\n",
      "Elapsed time: 43.42s\n",
      "\n",
      "42 0.684\n",
      "43 0.714\n",
      "44 0.714\n",
      "45 0.695\n",
      "46 0.69\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 9, 0.6994, 0.012419339757008003, 0.7699999999999999, 44.8313871383667)\n",
      "Elapsed time: 44.83s\n",
      "\n",
      "42 0.686\n",
      "43 0.69\n",
      "44 0.696\n",
      "45 0.697\n",
      "46 0.685\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 10, 0.6908000000000001, 0.004955804677345504, 0.773, 43.875915098190305)\n",
      "Elapsed time: 43.88s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from joblib import parallel_backend\n",
    "\n",
    "feature_selectors = [\n",
    "    (SelectFromModel, {\"threshold\": [-np.inf]}, \"max_features\", True),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        GradientBoostingClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [100],\n",
    "            \"learning_rate\": [0.1],\n",
    "            \"subsample\": [0.5],\n",
    "        },\n",
    "    ),\n",
    "    # (SVC, {\"kernel\": [\"rbf\"], \"probability\": [True], \"random_state\": [42]}),\n",
    "    # (QuadraticDiscriminantAnalysis, {}),\n",
    "]\n",
    "\n",
    "ks = np.arange(5, 11, 1)\n",
    "train_test_seeds = list(range(42, 47))\n",
    "\n",
    "with parallel_backend(\"threading\", n_jobs=-2):\n",
    "    run_experiment(feature_selectors, classifiers, ks, results, train_test_seeds)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
