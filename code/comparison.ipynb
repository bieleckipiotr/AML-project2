{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import (\n",
    "    RFE,\n",
    "    SelectFromModel,\n",
    "    SelectKBest,\n",
    "    SequentialFeatureSelector,\n",
    "    f_classif,\n",
    "    mutual_info_classif,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from utils import (\n",
    "    experiment,\n",
    "    get_data,\n",
    "    get_param_combinations,\n",
    "    get_params_json,\n",
    "    save_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change value before running experiment\n",
    "filename = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO remove - this is for testing the script!\n",
    "# X = X[:100]\n",
    "# y = y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(feature_selectors, classifiers, ks, results, train_test_seeds=[42]):\n",
    "    for fs in feature_selectors:\n",
    "        for clf in classifiers:\n",
    "            for k in ks:\n",
    "                # Generate parameter combinations\n",
    "                fs_cls, fs_params, k_param_name, requires_estimator = fs\n",
    "                clf_cls, clf_params = clf\n",
    "\n",
    "                fs_param_combinations = get_param_combinations(fs_params)\n",
    "                clf_param_combinations = get_param_combinations(clf_params)\n",
    "\n",
    "                for fs_params in fs_param_combinations:\n",
    "                    for clf_params in clf_param_combinations:\n",
    "                        result = experiment(\n",
    "                            X,\n",
    "                            y,\n",
    "                            fs_cls,\n",
    "                            fs_params,\n",
    "                            clf_cls,\n",
    "                            clf_params,\n",
    "                            k,\n",
    "                            k_param_name,\n",
    "                            requires_estimator,\n",
    "                            train_test_seeds,\n",
    "                        )\n",
    "\n",
    "                        print(result)\n",
    "                        print(f\"Elapsed time: {result[-1]:.2f}s\\n\")\n",
    "                        results.append(result)\n",
    "                        save_results(results, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - parameters of GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"comparison\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (\n",
    "        SelectKBest,\n",
    "        {\"score_func\": [f_classif, mutual_info_classif]},\n",
    "        \"k\",\n",
    "        False,\n",
    "    ),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        GradientBoostingClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.1, 0.2],\n",
    "            \"subsample\": [0.5, 1],\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "# ks = np.concatenate([np.arange(1, 20, 1), np.arange(20, 45, 5)])\n",
    "ks = np.arange(1, 21, 3)\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: simple feature selection with various classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (SelectKBest, {\"score_func\": [mutual_info_classif]}, \"k\", False),\n",
    "]\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    (GradientBoostingClassifier, {}),\n",
    "    (RandomForestClassifier, {\"random_state\": [42]}),\n",
    "    (SVC, {\"kernel\": [\"linear\", \"rbf\"], \"probability\": [True], \"random_state\": [42]}),\n",
    "    (LinearDiscriminantAnalysis, {}),\n",
    "    (QuadraticDiscriminantAnalysis, {}),\n",
    "]\n",
    "\n",
    "ks = np.arange(1, 21, 3)\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: simple classifier with various feature selectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (RFE, {}, \"n_features_to_select\", True),\n",
    "    (SelectFromModel, {\"threshold\": [-np.inf]}, \"max_features\", True),\n",
    "    (\n",
    "        SequentialFeatureSelector,\n",
    "        {\n",
    "            \"direction\": [\n",
    "                # \"backward\", # too slow\n",
    "                \"forward\",\n",
    "            ],\n",
    "            \"n_jobs\": [-2],\n",
    "        },\n",
    "        \"n_features_to_select\",\n",
    "        True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (RandomForestClassifier, {\"random_state\": [42]}),\n",
    "]\n",
    "\n",
    "ks = np.arange(1, 21, 3)\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: SelectFromModel with best classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"comparison_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (SelectFromModel, {\"threshold\": [-np.inf]}, \"max_features\", True),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        RandomForestClassifier,\n",
    "        {\"random_state\": [42], \"n_jobs\": [-2], \"n_estimators\": [100, 200]},\n",
    "    ),\n",
    "]\n",
    "\n",
    "ks = np.arange(1, 21, 1)\n",
    "train_test_seeds = list(range(42, 47))\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results, train_test_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"comparison_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "from joblib import parallel_backend\n",
    "\n",
    "feature_selectors = [\n",
    "    (SelectFromModel, {\"threshold\": [-np.inf]}, \"max_features\", True),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        GradientBoostingClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [100],\n",
    "            \"learning_rate\": [0.1],\n",
    "            \"subsample\": [0.5],\n",
    "        },\n",
    "    ),\n",
    "    # (SVC, {\"kernel\": [\"rbf\"], \"probability\": [True], \"random_state\": [42]}),\n",
    "    # (QuadraticDiscriminantAnalysis, {}),\n",
    "]\n",
    "\n",
    "ks = np.arange(5, 11, 1)\n",
    "train_test_seeds = list(range(42, 47))\n",
    "\n",
    "with parallel_backend(\"threading\", n_jobs=-2):\n",
    "    run_experiment(feature_selectors, classifiers, ks, results, train_test_seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5: XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"comparison_xgboost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\norbn\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyton-PwHrWJw5-py3.12\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:46:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 0.52\n",
      "43 0.534\n",
      "44 0.573\n",
      "45 0.507\n",
      "46 0.544\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'XGBClassifier', \"{'device': 'cuda'}\", 1, 0.5356, 0.022508664998173465, 0.58, 2.738766002655029)\n",
      "Elapsed time: 2.74s\n",
      "\n",
      "42 0.548\n",
      "43 0.571\n",
      "44 0.526\n",
      "45 0.527\n",
      "46 0.558\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'XGBClassifier', \"{'device': 'cuda'}\", 2, 0.546, 0.017515707236649036, 0.594, 2.976771831512451)\n",
      "Elapsed time: 2.98s\n",
      "\n",
      "42 0.568\n",
      "43 0.581\n",
      "44 0.55\n",
      "45 0.515\n",
      "46 0.596\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'XGBClassifier', \"{'device': 'cuda'}\", 3, 0.562, 0.027949955277245055, 0.641, 3.132274293899536)\n",
      "Elapsed time: 3.13s\n",
      "\n",
      "42 0.601\n",
      "43 0.621\n",
      "44 0.553\n",
      "45 0.547\n",
      "46 0.628\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'XGBClassifier', \"{'device': 'cuda'}\", 4, 0.5900000000000001, 0.03389395226290375, 0.6890000000000001, 2.9012763500213623)\n",
      "Elapsed time: 2.90s\n",
      "\n",
      "42 0.641\n",
      "43 0.623\n",
      "44 0.564\n",
      "45 0.594\n",
      "46 0.627\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'XGBClassifier', \"{'device': 'cuda'}\", 5, 0.6097999999999999, 0.027534705373401063, 0.681, 2.728695440292358)\n",
      "Elapsed time: 2.73s\n",
      "\n",
      "42 0.625\n",
      "43 0.618\n",
      "44 0.596\n",
      "45 0.606\n",
      "46 0.627\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'XGBClassifier', \"{'device': 'cuda'}\", 6, 0.6144000000000001, 0.01177454882362803, 0.6950000000000001, 2.7070542335510255)\n",
      "Elapsed time: 2.71s\n",
      "\n",
      "42 0.635\n",
      "43 0.641\n",
      "44 0.616\n",
      "45 0.651\n",
      "46 0.616\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'XGBClassifier', \"{'device': 'cuda'}\", 7, 0.6318, 0.013876599006961336, 0.705, 2.7419901847839356)\n",
      "Elapsed time: 2.74s\n",
      "\n",
      "42 0.642\n",
      "43 0.655\n",
      "44 0.632\n",
      "45 0.638\n",
      "46 0.645\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'XGBClassifier', \"{'device': 'cuda'}\", 8, 0.6424000000000001, 0.007657675887630664, 0.704, 2.703707218170166)\n",
      "Elapsed time: 2.70s\n",
      "\n",
      "42 0.644\n",
      "43 0.667\n",
      "44 0.619\n",
      "45 0.644\n",
      "46 0.654\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'XGBClassifier', \"{'device': 'cuda'}\", 9, 0.6456, 0.01575563391298492, 0.7070000000000001, 2.753081750869751)\n",
      "Elapsed time: 2.75s\n",
      "\n",
      "42 0.674\n",
      "43 0.671\n",
      "44 0.611\n",
      "45 0.628\n",
      "46 0.634\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'XGBClassifier', \"{'device': 'cuda'}\", 10, 0.6436, 0.024791934172226276, 0.728, 2.9069538593292235)\n",
      "Elapsed time: 2.91s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from joblib import parallel_backend\n",
    "\n",
    "feature_selectors = [\n",
    "    (SelectFromModel, {\"threshold\": [-np.inf]}, \"max_features\", True),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        xgb.XGBClassifier,\n",
    "        # {},\n",
    "        {\"device\": [\"cuda\"]},\n",
    "    ),\n",
    "]\n",
    "\n",
    "ks = np.arange(1, 11, 1)\n",
    "train_test_seeds = list(range(42, 47))\n",
    "\n",
    "with parallel_backend(\"threading\", n_jobs=-2):\n",
    "    run_experiment(feature_selectors, classifiers, ks, results, train_test_seeds)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
