{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import (\n",
    "    RFE,\n",
    "    SelectFromModel,\n",
    "    SelectKBest,\n",
    "    SequentialFeatureSelector,\n",
    "    f_classif,\n",
    "    mutual_info_classif,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../data/x_train.txt\", sep=\" \", header=None)\n",
    "y = pd.read_csv(\"../data/y_train.txt\", header=None)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "y = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change value before running experiment\n",
    "filename = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO remove - this is for testing the script!\n",
    "# X = X[:100]\n",
    "# y = y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_combinations(param_dict):\n",
    "    value_prod = list(product(*param_dict.values()))\n",
    "    keys = param_dict.keys()\n",
    "    return [dict(zip(keys, values)) for values in value_prod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_json_to_str(param_json):\n",
    "    if type(param_json).__name__ == \"function\":\n",
    "        return param_json.__name__\n",
    "    return param_json\n",
    "\n",
    "\n",
    "def get_params_json(params):\n",
    "    params_mapped = {k: param_json_to_str(v) for k, v in params.items()}\n",
    "    return json.dumps(params_mapped).replace('\"', \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(\n",
    "    fs_cls,\n",
    "    fs_kwargs,\n",
    "    clf_cls,\n",
    "    clf_kwargs,\n",
    "    n_features,\n",
    "    k_param_name,\n",
    "    requires_estimator,\n",
    "    train_test_seeds,\n",
    "):\n",
    "    clf = clf_cls(**clf_kwargs)\n",
    "\n",
    "    fs_kwargs = {\n",
    "        k_param_name: n_features,\n",
    "        **fs_kwargs,\n",
    "    }\n",
    "    if requires_estimator:\n",
    "        feature_selector = fs_cls(estimator=clf, **fs_kwargs)\n",
    "    else:\n",
    "        feature_selector = fs_cls(**fs_kwargs)\n",
    "\n",
    "    accs = []\n",
    "    accs_top_20pc = []\n",
    "\n",
    "    for seed in train_test_seeds:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            test_size=0.2,\n",
    "            stratify=y,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "        # Feature selection\n",
    "        X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "        X_test = feature_selector.transform(X_test)\n",
    "\n",
    "        # Training\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Prediction\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        proba_1 = clf.predict_proba(X_test)[:, 1]\n",
    "        proba_1 = np.array([proba_1, y_test]).T\n",
    "        proba_1 = proba_1[proba_1[:, 0].argsort()][::-1]\n",
    "\n",
    "        # Evaluation\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        top_20pc = proba_1[: int(len(proba_1) * 0.2)]\n",
    "        acc_top_20pc = accuracy_score(top_20pc[:, 1], np.round(top_20pc[:, 0]))\n",
    "\n",
    "        print(seed, acc)\n",
    "\n",
    "        accs.append(acc)\n",
    "        accs_top_20pc.append(acc_top_20pc)\n",
    "\n",
    "    return np.array(accs), np.array(accs_top_20pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results):\n",
    "    df = pd.DataFrame(\n",
    "        results,\n",
    "        columns=[\n",
    "            \"feature_selector\",\n",
    "            \"feature_selector_params\",\n",
    "            \"classifier\",\n",
    "            \"classifier_params\",\n",
    "            \"n_features\",\n",
    "            \"accuracy\",\n",
    "            \"accuracy_std\",\n",
    "            \"accuracy_top_20pc\",\n",
    "            \"elapsed_time\",\n",
    "        ],\n",
    "    )\n",
    "    df.to_csv(f\"../results/{filename}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(feature_selectors, classifiers, ks, results, train_test_seeds=[42]):\n",
    "    for fs in feature_selectors:\n",
    "        for clf in classifiers:\n",
    "            for k in ks:\n",
    "                # Generate parameter combinations\n",
    "                fs_cls, fs_params, k_param_name, requires_estimator = fs\n",
    "                clf_cls, clf_params = clf\n",
    "\n",
    "                fs_param_combinations = get_param_combinations(fs_params)\n",
    "                clf_param_combinations = get_param_combinations(clf_params)\n",
    "\n",
    "                for fs_params in fs_param_combinations:\n",
    "                    for clf_params in clf_param_combinations:\n",
    "                        # Run experiment\n",
    "                        start = time.time()\n",
    "                        accs, accs_top_20pc = experiment(\n",
    "                            fs_cls,\n",
    "                            fs_params,\n",
    "                            clf_cls,\n",
    "                            clf_params,\n",
    "                            k,\n",
    "                            k_param_name,\n",
    "                            requires_estimator,\n",
    "                            train_test_seeds,\n",
    "                        )\n",
    "                        elapsed = time.time() - start\n",
    "                        elapsed = elapsed / len(train_test_seeds)\n",
    "\n",
    "                        acc = accs.mean()\n",
    "                        acc_std = accs.std()\n",
    "                        acc_top_20pc = accs_top_20pc.mean()\n",
    "\n",
    "                        # Save results\n",
    "                        result = (\n",
    "                            fs_cls.__name__,\n",
    "                            get_params_json(fs_params),\n",
    "                            clf_cls.__name__,\n",
    "                            get_params_json(clf_params),\n",
    "                            k,\n",
    "                            acc,\n",
    "                            acc_std,\n",
    "                            acc_top_20pc,\n",
    "                            elapsed,\n",
    "                        )\n",
    "\n",
    "                        print(result)\n",
    "                        print(f\"Elapsed time: {elapsed:.2f}s\\n\")\n",
    "                        results.append(result)\n",
    "                        save_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - parameters of GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"comparison\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (\n",
    "        SelectKBest,\n",
    "        {\"score_func\": [f_classif, mutual_info_classif]},\n",
    "        \"k\",\n",
    "        False,\n",
    "    ),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        GradientBoostingClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.1, 0.2],\n",
    "            \"subsample\": [0.5, 1],\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "# ks = np.concatenate([np.arange(1, 20, 1), np.arange(20, 45, 5)])\n",
    "ks = np.arange(1, 21, 3)\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: simple feature selection with various classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (SelectKBest, {\"score_func\": [mutual_info_classif]}, \"k\", False),\n",
    "]\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    (GradientBoostingClassifier, {}),\n",
    "    (RandomForestClassifier, {\"random_state\": [42]}),\n",
    "    (SVC, {\"kernel\": [\"linear\", \"rbf\"], \"probability\": [True], \"random_state\": [42]}),\n",
    "    (LinearDiscriminantAnalysis, {}),\n",
    "    (QuadraticDiscriminantAnalysis, {}),\n",
    "]\n",
    "\n",
    "ks = np.arange(1, 21, 3)\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: simple classifier with various feature selectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (RFE, {}, \"n_features_to_select\", True),\n",
    "    (SelectFromModel, {\"threshold\": [-np.inf]}, \"max_features\", True),\n",
    "    (\n",
    "        SequentialFeatureSelector,\n",
    "        {\n",
    "            \"direction\": [\n",
    "                # \"backward\", # too slow\n",
    "                \"forward\",\n",
    "            ],\n",
    "            \"n_jobs\": [-2],\n",
    "        },\n",
    "        \"n_features_to_select\",\n",
    "        True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (RandomForestClassifier, {\"random_state\": [42]}),\n",
    "]\n",
    "\n",
    "ks = np.arange(1, 21, 3)\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: SelectFromModel with best classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"comparison_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "feature_selectors = [\n",
    "    (SelectFromModel, {\"threshold\": [-np.inf]}, \"max_features\", True),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        RandomForestClassifier,\n",
    "        {\"random_state\": [42], \"n_jobs\": [-2], \"n_estimators\": [100, 200]},\n",
    "    ),\n",
    "]\n",
    "\n",
    "ks = np.arange(1, 21, 1)\n",
    "train_test_seeds = list(range(42, 47))\n",
    "\n",
    "run_experiment(feature_selectors, classifiers, ks, results, train_test_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"comparison_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 0.669\n",
      "43 0.683\n",
      "44 0.68\n",
      "45 0.684\n",
      "46 0.679\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 5, 0.679, 0.005329165037789696, 0.768, 45.349039268493655)\n",
      "Elapsed time: 45.35s\n",
      "\n",
      "42 0.693\n",
      "43 0.702\n",
      "44 0.712\n",
      "45 0.697\n",
      "46 0.7\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 6, 0.7008000000000001, 0.0063686733312362685, 0.766, 48.50391154289245)\n",
      "Elapsed time: 48.50s\n",
      "\n",
      "42 0.689\n",
      "43 0.695\n",
      "44 0.698\n",
      "45 0.698\n",
      "46 0.693\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 7, 0.6946, 0.0033823069050575557, 0.779, 44.32134146690369)\n",
      "Elapsed time: 44.32s\n",
      "\n",
      "42 0.679\n",
      "43 0.693\n",
      "44 0.701\n",
      "45 0.691\n",
      "46 0.698\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 8, 0.6923999999999999, 0.007578918128598534, 0.781, 43.42149753570557)\n",
      "Elapsed time: 43.42s\n",
      "\n",
      "42 0.684\n",
      "43 0.714\n",
      "44 0.714\n",
      "45 0.695\n",
      "46 0.69\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 9, 0.6994, 0.012419339757008003, 0.7699999999999999, 44.8313871383667)\n",
      "Elapsed time: 44.83s\n",
      "\n",
      "42 0.686\n",
      "43 0.69\n",
      "44 0.696\n",
      "45 0.697\n",
      "46 0.685\n",
      "('SelectFromModel', \"{'threshold': -Infinity}\", 'GradientBoostingClassifier', \"{'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.5}\", 10, 0.6908000000000001, 0.004955804677345504, 0.773, 43.875915098190305)\n",
      "Elapsed time: 43.88s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from joblib import parallel_backend\n",
    "\n",
    "feature_selectors = [\n",
    "    (SelectFromModel, {\"threshold\": [-np.inf]}, \"max_features\", True),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        GradientBoostingClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [100],\n",
    "            \"learning_rate\": [0.1],\n",
    "            \"subsample\": [0.5],\n",
    "        },\n",
    "    ),\n",
    "    # (SVC, {\"kernel\": [\"rbf\"], \"probability\": [True], \"random_state\": [42]}),\n",
    "    # (QuadraticDiscriminantAnalysis, {}),\n",
    "]\n",
    "\n",
    "ks = np.arange(5, 11, 1)\n",
    "train_test_seeds = list(range(42, 47))\n",
    "\n",
    "with parallel_backend(\"threading\", n_jobs=-2):\n",
    "    run_experiment(feature_selectors, classifiers, ks, results, train_test_seeds)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
