{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import (\n",
    "    RFE,\n",
    "    SelectFromModel,\n",
    "    SelectKBest,\n",
    "    SequentialFeatureSelector,\n",
    "    f_classif,\n",
    "    mutual_info_classif,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import get_data, get_param_combinations, get_params_json, save_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_data()\n",
    "\n",
    "# X = X[:50, :10]\n",
    "# y = y[:50]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11  60   9  24  38  28  43  75   7  16 190 357 384 158 412 358 484 344\n",
      " 260 296  48  31 281 367 442 275 225 146 142 144 286 417 360 497 161 120\n",
      "  46 394 188  93 439 111 429 332  76  67 333 343 385 431  52 376 294  39\n",
      " 459 387 476  40 415 136  90 407 486 346 218 390 366  68 460 256 169 496\n",
      " 249 124 119 150 389 401  30 462 129 271 299 156 139 221 269 101 311 457\n",
      " 105 245 334 482 183 411 368 132 180 216   2   3   4   5   6   1 103 270\n",
      "  32  14 316 237  92   8 449 186 210  99 436 310  63 227  83  66 261 481\n",
      " 100 409 438 107 489  53 354  29 240 226 248 371 151  25 477 464 178 195\n",
      " 336 117 181 356 140 471 283 340  96 135 267  98 171  45  71 416 313  37\n",
      " 395 341 211 182 325 396 468 230 164 372 443 405 223  41  55  26 217 465\n",
      " 263 450  35 455 208 492 258 365 369 280  81 116 430 172 363 469 303 479\n",
      " 108  87 187 274  78 207 302 179 138 262  59 342 452 157 392  22  18  70\n",
      "  73 102 490 420  94 214 317 282 279 131 381 253 137 498 143 422 461 235\n",
      "  79 122 500 273 185 448 322  13 424  77 288 485  47 166  88 348 229 121\n",
      " 110 106 330 154  82 370 222 212 472 277 268 353  64  69 202 350 123 495\n",
      "  42 432 219 285 458 403 378 404 243 410 228  12 402  57 236 324 272  15\n",
      " 295 297 315 254 292 134 319  19 234 194 418 494  97 399  74 198 203 349\n",
      " 220 338 242 133 168 145 300 266  84 487  27 499 426  56 328  23 189  36\n",
      "  17 147 470 114 113  54 206 463 173 474 446 170 327 444 257 160 289 337\n",
      " 473 205 380 359 374 265 398 375 441  20 434 445 305 326 231  49 400  62\n",
      "  33 213 377 259 451 361 433 276 197 304 423 244 112  21 335 255 209 199\n",
      " 419 193 238  86 314 397 247 290 200 284 109 251 250  10 130 191 406 118\n",
      " 128 339 278 388 352 306 466  72 167 163 233 148 456 115 241 153 126 408\n",
      " 298 329 488 427 127 152  58 440  61 320 264 428 480 437 382 351 155 239\n",
      " 201 383 379 246 184 478 301  44 414 364 175 252 196 162 174  50 321 318\n",
      " 373  91 165 491 453 177 307 192  85 159  51 413  65 149  34 391 393 355\n",
      " 425 421 125 347 232 475 386 362 293 345 308 467 331 291 287 309 483 224\n",
      "  95 176 215  80 454 312 447 323 104 435 141 493  89 204]\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "# model = GradientBoostingClassifier(random_state=42)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "selector = RFE(model, n_features_to_select=1)\n",
    "\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "print(selector.ranking_)\n",
    "print(selector.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    zip(selector.ranking_, selector.support_), columns=[\"Ranking\", \"Support\"]\n",
    ").to_csv(\"../results/rfe_rf.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
